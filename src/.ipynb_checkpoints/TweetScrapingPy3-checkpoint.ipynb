{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (3.7.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (2.21.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.3.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\n",
      "Requirement already satisfied: pandas in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already up-to-date: textblob in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from textblob) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: preprocessor in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (1.1.3)\n",
      "Requirement already satisfied: tweet-preprocessor in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied: sklearn in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "Requirement already satisfied: argparse in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already up-to-date: nltk in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/User/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tweepy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install -U textblob\n",
    "!{sys.executable} -m pip install preprocessor\n",
    "!{sys.executable} -m pip install tweet-preprocessor\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install argparse\n",
    "!{sys.executable} -m pip install -U nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "import sklearn\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor.api as p\n",
    "import argparse\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = 'Lydypy5GRHslhuWsXTAagVFpO'\n",
    "consumer_secret = 'K9HA6MyfRWm73G50WHvzBPxfY0gWfJRk5ajcUmGRCg4e9NiM69'\n",
    "access_key= '789687511-BGbhUzj8zVLk9HeKKxrCZnzJ21xb3qXqZMHyf0gX'\n",
    "access_secret = 'kIDmi6vhOiePyEIZ5XXrOV8rl0xLOe5wLQ2XbhH2qCLsr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#declare file paths as follows for three files\n",
    "democrat_tweets = \"/Users/User/221project/data/senate_democrat_data.csv\"\n",
    "republican_tweets = \"/Users/User/221project/data/senate_republican_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#columns of the csv file\n",
    "COLS = ['id', 'original_text','clean_text', 'sentiment','polarity', 'subjectivity', 'hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    " \n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "#after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    tweet = re.sub(r'RT *[^:]*:','', tweet);\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#remove url\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = []\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in emoticons and w not in string.punctuation:\n",
    "            if w[0] == \".\":\n",
    "                continue\n",
    "            w = re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', w)\n",
    "            w = w.lower()\n",
    "            \n",
    "            if len(w) == 1 and w not in ['a', 'e', 'i','o','u']:\n",
    "                continue\n",
    "            elif len(w) == 2 and w[0] in string.punctuation:\n",
    "                continue\n",
    "            filtered_tweet.append(w.lower())\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def write_tweets(handle, file):\n",
    "    #If the file exists, then read the existing data from the CSV file.\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file, header=0)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=COLS)\n",
    "    #page attribute in tweepy.cursor and iteration\n",
    "    for page in tweepy.Cursor(api.user_timeline, id=handle,\n",
    "                              count=200, include_rts=True, tweet_mode = 'extended').pages():\n",
    "        for status in page:\n",
    "            new_entry = []\n",
    "            status = status._json\n",
    "    \n",
    "            #status['text'] = status['text'].replace(\"#\", \"\")\n",
    "            if \"retweeted_status\" in status:\n",
    "                status['full_text'] = status[\"retweeted_status\"]['full_text']\n",
    "            status['full_text'] = status['full_text'].replace(\"@\", \"\")\n",
    "            clean_text = p.clean(status['full_text'])\n",
    "            filtered_tweet=clean_tweets(clean_text)\n",
    "            \n",
    "            blob = TextBlob(filtered_tweet)\n",
    "            Sentiment = blob.sentiment     \n",
    "            polarity = Sentiment.polarity\n",
    "            subjectivity = Sentiment.subjectivity\n",
    "            \n",
    "            new_entry += [status['id'],status['full_text'], filtered_tweet, Sentiment,polarity,subjectivity]\n",
    "            hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "            new_entry.append(hashtags) #append the hashtags\n",
    "            \n",
    "            df_final = df.append(single_tweet_df, ignore_index=True)\n",
    "            \n",
    "            csvFile = open(file, 'a+' ,encoding='utf-8')\n",
    "            df.to_csv(csvFile, mode='a', columns=COLS, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "democrat_handle = \"SenateDems\"\n",
    "republican_handle = \"SenateGOP\"\n",
    "\n",
    "write_tweets(democrat_handle, democrat_tweets)\n",
    "write_tweets(republican_handle, republican_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
